{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_values = pd.read_csv('data/train_values.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "test_values = pd.read_csv('data/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "X = train_values.iloc[:,15:25]\n",
    "X = pd.get_dummies(X, prefix_sep='_')\n",
    "\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(scale(X))\n",
    "\n",
    "PCA_df = pd.DataFrame(data=principalComponents[:,:5], columns=['PC1','PC2','PC3','PC4','PC5'])\n",
    "\n",
    "# Add PCA components to DF\n",
    "new_train_values = pd.concat([train_values, PCA_df], axis=1)\n",
    "\n",
    "# Drop columns used for PCA\n",
    "# columns #15 ~ #25: \"count_floors_pre_eq\" ~ \"plan_configuration\"\n",
    "drop_list = new_train_values.columns[15:26]\n",
    "new_train_values.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = pd.merge(new_train_values, train_labels, on=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1_count = pd.DataFrame(new_train_df['geo_level_1_id'].value_counts().sort_index())\n",
    "geo2_count = pd.DataFrame(new_train_df['geo_level_2_id'].value_counts().sort_index())\n",
    "geo3_count = pd.DataFrame(new_train_df['geo_level_3_id'].value_counts().sort_index())\n",
    "\n",
    "geo1_count.rename(columns={\"geo_level_1_id\":\"counts\"}, inplace=True)\n",
    "geo2_count.rename(columns={\"geo_level_2_id\":\"counts\"}, inplace=True)\n",
    "geo3_count.rename(columns={\"geo_level_3_id\":\"counts\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_geo1 = list(range(31))\n",
    "a = pd.DataFrame()\n",
    "a['id'] = index_geo1\n",
    "geo1_count=pd.merge(a, geo1_count, how='left', left_on='id', right_index=True)\n",
    "geo1_count=geo1_count.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/1945352171.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam1_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==1])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/1945352171.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam2_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==2])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/1945352171.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam3_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==3])\n"
     ]
    }
   ],
   "source": [
    "dam1 = []\n",
    "\n",
    "for i in range(0,31):\n",
    "    dam1_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==1])\n",
    "    dam1.append(dam1_count)\n",
    "\n",
    "geo1_count[\"damage_1\"] = pd.DataFrame(dam1)\n",
    "\n",
    "dam2 = []\n",
    "\n",
    "for i in range(0,31):\n",
    "    dam2_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==2])\n",
    "    dam2.append(dam2_count)\n",
    "\n",
    "geo1_count[\"damage_2\"] = pd.DataFrame(dam2)\n",
    "\n",
    "dam3 = []\n",
    "\n",
    "for i in range(0,31):\n",
    "    dam3_count = len(new_train_df[new_train_df.geo_level_1_id==i][new_train_df.damage_grade==3])\n",
    "    dam3.append(dam3_count)\n",
    "\n",
    "geo1_count[\"damage_3\"] = pd.DataFrame(dam3)\n",
    "\n",
    "geo1_count['geo1_dam1_prob'] = geo1_count['damage_1'] / geo1_count['counts']\n",
    "geo1_count['geo1_dam2_prob'] = geo1_count['damage_2'] / geo1_count['counts']\n",
    "geo1_count['geo1_dam3_prob'] = geo1_count['damage_3'] / geo1_count['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_geo2 = list(range(1428))\n",
    "a = pd.DataFrame()\n",
    "a['id'] = index_geo2\n",
    "geo2_count=pd.merge(a, geo2_count, how='left', left_on='id', right_index=True)\n",
    "geo2_count=geo2_count.interpolate()\n",
    "#geo2_count.drop(\"id\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3585502810.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam1_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==1])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3585502810.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam2_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==2])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3585502810.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam3_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==3])\n"
     ]
    }
   ],
   "source": [
    "dam1 = []\n",
    "\n",
    "for i in range(0,1428):\n",
    "    dam1_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==1])\n",
    "    dam1.append(dam1_count)\n",
    "\n",
    "geo2_count[\"damage_1\"] = pd.DataFrame(dam1)\n",
    "\n",
    "dam2 = []\n",
    "\n",
    "for i in range(0,1428):\n",
    "    dam2_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==2])\n",
    "    dam2.append(dam2_count)\n",
    "\n",
    "geo2_count[\"damage_2\"] = pd.DataFrame(dam2)\n",
    "\n",
    "dam3 = []\n",
    "\n",
    "for i in range(0,1428):\n",
    "    dam3_count = len(new_train_df[new_train_df.geo_level_2_id==i][new_train_df.damage_grade==3])\n",
    "    dam3.append(dam3_count)\n",
    "\n",
    "geo2_count[\"damage_3\"] = pd.DataFrame(dam3)\n",
    "geo2_count=geo2_count.interpolate()\n",
    "\n",
    "geo2_count['geo2_dam1_prob'] = geo2_count['damage_1'] / geo2_count['counts']\n",
    "geo2_count['geo2_dam2_prob'] = geo2_count['damage_2'] / geo2_count['counts']\n",
    "geo2_count['geo2_dam3_prob'] = geo2_count['damage_3'] / geo2_count['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_geo3 = list(range(12568))\n",
    "b = pd.DataFrame()\n",
    "b['id'] = index_geo3\n",
    "geo3_count=pd.merge(b, geo3_count, how='left', left_on='id', right_index=True)\n",
    "geo3_count=geo3_count.interpolate()\n",
    "##geo3_count.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3103804941.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam1_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==1])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3103804941.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam2_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==2])\n",
      "/var/folders/gm/kys_b_lx5n153wpkc5l01s280000gn/T/ipykernel_49724/3103804941.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dam3_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==3])\n"
     ]
    }
   ],
   "source": [
    "dam1 = []\n",
    "\n",
    "for i in range(0,12568):\n",
    "    dam1_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==1])\n",
    "    dam1.append(dam1_count)\n",
    "\n",
    "geo3_count[\"damage_1\"] = pd.DataFrame(dam1)\n",
    "\n",
    "dam2 = []\n",
    "\n",
    "for i in range(0,12568):\n",
    "    dam2_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==2])\n",
    "    dam2.append(dam2_count)\n",
    "\n",
    "geo3_count[\"damage_2\"] = pd.DataFrame(dam2)\n",
    "\n",
    "dam3 = []\n",
    "\n",
    "for i in range(0,12568):\n",
    "    dam3_count = len(new_train_df[new_train_df.geo_level_3_id==i][new_train_df.damage_grade==3])\n",
    "    dam3.append(dam3_count)\n",
    "\n",
    "geo3_count[\"damage_3\"] = pd.DataFrame(dam3)\n",
    "geo3_count=geo3_count.interpolate()\n",
    "\n",
    "geo3_count['geo3_dam1_prob'] = geo3_count['damage_1'] / geo3_count['counts']\n",
    "geo3_count['geo3_dam2_prob'] = geo3_count['damage_2'] / geo3_count['counts']\n",
    "geo3_count['geo3_dam3_prob'] = geo3_count['damage_3'] / geo3_count['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260596</th>\n",
       "      <td>688636</td>\n",
       "      <td>25</td>\n",
       "      <td>1335</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260597</th>\n",
       "      <td>669485</td>\n",
       "      <td>17</td>\n",
       "      <td>715</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260598</th>\n",
       "      <td>602512</td>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>8163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260599</th>\n",
       "      <td>151409</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260600</th>\n",
       "      <td>747594</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260601 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id\n",
       "0            802906               6             487           12198\n",
       "1             28830               8             900            2812\n",
       "2             94947              21             363            8973\n",
       "3            590882              22             418           10694\n",
       "4            201944              11             131            1488\n",
       "...             ...             ...             ...             ...\n",
       "260596       688636              25            1335            1621\n",
       "260597       669485              17             715            2060\n",
       "260598       602512              17              51            8163\n",
       "260599       151409              26              39            1851\n",
       "260600       747594              21               9            9101\n",
       "\n",
       "[260601 rows x 4 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_table = new_train_df.iloc[:,0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = geo1_count.iloc[:,[0,5,6,7]]\n",
    "prob_table = pd.merge(prob_table, temp, how=\"left\", left_on=\"geo_level_1_id\", right_on=\"id\")\n",
    "prob_table.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "temp2 = geo2_count.iloc[:,[0,5,6,7]]\n",
    "prob_table = pd.merge(prob_table, temp2, how=\"left\", left_on=\"geo_level_2_id\", right_on=\"id\")\n",
    "prob_table.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "temp3 = geo3_count.iloc[:,[0,5,6,7]]\n",
    "prob_table = pd.merge(prob_table, temp3, how=\"left\", left_on=\"geo_level_3_id\", right_on=\"id\")\n",
    "prob_table.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "prob_table.drop([\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = pd.merge(new_train_df, prob_table, how=\"left\", left_on=\"building_id\", right_on=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list2 = new_train_df.columns[14:28]\n",
    "new_train_df.drop(drop_list2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = pd.get_dummies(new_train_df, prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_labels = new_train_df['damage_grade']\n",
    "new_train_df.drop(['building_id','damage_grade','geo_level_1_id','geo_level_2_id','geo_level_3_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "### Clean Test Values\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "X2 = test_values.iloc[:,15:25]\n",
    "X2 = pd.get_dummies(X2, prefix_sep='_')\n",
    "\n",
    "pca_test = PCA()\n",
    "principalComponents_test = pca_test.fit_transform(scale(X2))\n",
    "\n",
    "PCA_df_test = pd.DataFrame(data=principalComponents_test[:,:5], columns=['PC1','PC2','PC3','PC4','PC5'])\n",
    "\n",
    "test_values = pd.concat([test_values, PCA_df_test], axis=1)\n",
    "\n",
    "# Drop columns used for PCA\n",
    "# columns #15 ~ #25: \"count_floors_pre_eq\" ~ \"plan_configuration\"\n",
    "drop_list2 = test_values.columns[15:26]\n",
    "test_values.drop(drop_list2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300051</td>\n",
       "      <td>17</td>\n",
       "      <td>596</td>\n",
       "      <td>11307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99355</td>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>11987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>890251</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745817</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>421793</td>\n",
       "      <td>17</td>\n",
       "      <td>289</td>\n",
       "      <td>7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86863</th>\n",
       "      <td>310028</td>\n",
       "      <td>4</td>\n",
       "      <td>605</td>\n",
       "      <td>3623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86864</th>\n",
       "      <td>663567</td>\n",
       "      <td>10</td>\n",
       "      <td>1407</td>\n",
       "      <td>11907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86865</th>\n",
       "      <td>1049160</td>\n",
       "      <td>22</td>\n",
       "      <td>1136</td>\n",
       "      <td>7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86866</th>\n",
       "      <td>442785</td>\n",
       "      <td>6</td>\n",
       "      <td>1041</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86867</th>\n",
       "      <td>501372</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>6436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id\n",
       "0           300051              17             596           11307\n",
       "1            99355               6             141           11987\n",
       "2           890251              22              19           10044\n",
       "3           745817              26              39             633\n",
       "4           421793              17             289            7970\n",
       "...            ...             ...             ...             ...\n",
       "86863       310028               4             605            3623\n",
       "86864       663567              10            1407           11907\n",
       "86865      1049160              22            1136            7712\n",
       "86866       442785               6            1041             912\n",
       "86867       501372              26              36            6436\n",
       "\n",
       "[86868 rows x 4 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_table2 = test_values.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = geo1_count.iloc[:,[0,5,6,7]]\n",
    "prob_table2 = pd.merge(prob_table2, temp, how=\"left\", left_on=\"geo_level_1_id\", right_on=\"id\")\n",
    "prob_table2.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "temp2 = geo2_count.iloc[:,[0,5,6,7]]\n",
    "prob_table2 = pd.merge(prob_table2, temp2, how=\"left\", left_on=\"geo_level_2_id\", right_on=\"id\")\n",
    "prob_table2.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "temp3 = geo3_count.iloc[:,[0,5,6,7]]\n",
    "prob_table2 = pd.merge(prob_table2, temp3, how=\"left\", left_on=\"geo_level_3_id\", right_on=\"id\")\n",
    "prob_table2.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "prob_table2.drop([\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.merge(test_values, prob_table2, how=\"left\", left_on=\"building_id\", right_on=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list3 = test_values.columns[14:28]\n",
    "test_values.drop(drop_list3, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.get_dummies(test_values, prefix_sep='_')\n",
    "test_values.drop(['building_id','geo_level_1_id','geo_level_2_id','geo_level_3_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv('V3_train_feat_engineered.csv')\n",
    "new_train_labels.to_csv('V3_train_labels_feat_engineered.csv')\n",
    "test_values.to_csv('V3_test_feat_engineered.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84a28415a0fce399251a00d99c6f10afc2f0abd901e5a1ee0ec430f3f3d70f7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
